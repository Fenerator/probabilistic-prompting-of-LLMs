{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/dug/Desktop/exp_3_set_proba_V4')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json, os, sys, re\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy import stats\n",
    "from scipy.stats import entropy\n",
    "from datasets import load_dataset, Dataset\n",
    "import itertools\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from scipy.special import softmax\n",
    "import pickle\n",
    "from joblib import Parallel, delayed\n",
    "import language_tool_python\n",
    "from itertools import combinations\n",
    "# add src folder to path\n",
    "sys.path.append('..')\n",
    "\n",
    "from dev.ProbLM import JointLM, ConditionalLM\n",
    "from exp_3_set_proba.prepare_data import correct_grammar, few_shot_examples \n",
    "from exp_3_set_proba.analyze import calculate_ranking, calculate_instance_probability # was calculate_p_t_V2\n",
    "\n",
    "from exp_3_set_proba.utils import hist_of_all_p_t_values, classify, stacked_p_t_plot, hist_of_all_p_t_values, evaluate_classifier, boxplots, scatterplots, calculate_macro_avg, plot_roc_curve, plot_coverage_risk_curve_2, calculate_entropies, get_data_permutations\n",
    "from exp_3_set_proba.utils import get_data, save_plot, combine_stats_dfs\n",
    "from dev.ProbLM import JointLM, ConditionalLM\n",
    "\n",
    "\n",
    "from data_utils import get_wiki_summary\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "HOME_PATH = os.path.expanduser(\"~/\")\n",
    "\n",
    "BASE_PATH = Path(f\"{HOME_PATH}/Desktop/exp_3_set_proba_V4/\") # TODO\n",
    "\n",
    "stat_metrics  = ['n_objs', 'n_subjs', 'n_para', 'n_instances',\n",
    "       'dataset', 'model', 'run_name']\n",
    "metrics_global = ['coverage_abs', 'coverage_rel','precision_global', 'recall_global', 'f1_global',\n",
    "       'accuracy_global', 'fpr_global', \n",
    "       'precision_argmax_global', 'recall_argmax_global', 'f1_argmax_global',\n",
    "       'accuracy_argmax_global',  'fpr_argmax_global',\n",
    "       ] # others: 'tp_global', 'tn_global', 'fp_global', 'fn_global', 'tp_argmax_global', 'tn_argmax_global', 'fp_argmax_global', 'fn_argmax_global',\n",
    "metrics_selective = ['precision_selective']\n",
    "metrics_global_0_thershold = ['auc_global', 'fpr_by_threshold_global',\n",
    "       'tpr_by_threshold_global', 'roc_thresholds_global', 'fpr_by_threshold_argmax_global', 'tpr_by_threshold_argmax_global',\n",
    "       'roc_thresholds_argmax_global', 'auc_argmax_global']\n",
    "metrics_per_paraphrase = ['precision_argmax_pp', 'recall_argmax_pp', 'f1_argmax_pp',\n",
    "       'accuracy_argmax_pp', 'fpr_argmax_pp'] # others: 'tp_argmax_pp', 'tn_argmax_pp', 'fp_argmax_pp','fn_argmax_pp',\n",
    "metrics_per_paraphrase_0_threshold = ['fpr_by_threshold_argmax_pp',\n",
    "       'tpr_by_threshold_argmax_pp', 'roc_thresholds_argmax_pp', 'auc_argmax_pp']\n",
    "\n",
    "BASE_PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['r_s_id', 'o_permutation_n', 'sub_label', 'obj_label', 'sequence',\n",
       "       'label', 'orig_relation_template', 'orig_relation_id',\n",
       "       'paraphrased_relation_template', 'paraphrase_id', 'sequence_original',\n",
       "       'log_seq_prob', 's_r_t_id', 'p_t_s_r', 'p_t_over_paraphrases', 'p_t',\n",
       "       'rank_o', 'rank_o|p_t_s_r,r_s_t(r)_i'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_names = ['hypernymy_2000_50_mistral7B', 'trex_test_2000_50_mistral7B', 'PopQA_test_2000_50_mistral7B']\n",
    "dataset_per_run = ['hypernymy']#, 'trex', 'PopQA']\n",
    "df_stats, df_instance_permutations = get_data(run_names[0], BASE_PATH)\n",
    "df_instance_permutations['obj_label'].nunique()\n",
    "\n",
    "df_instance_permutations.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset for Manual Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select random subset per relation \n",
    "RERUN = False # Overwrite annotated data!\n",
    "n = 1\n",
    "# 50% pos / 50% neg / 2 of each paraphrase template\n",
    "\n",
    "if RERUN:\n",
    "    for r, run_name in enumerate(run_names):\n",
    "        df_stats, df_instance_permutations = get_data(run_name, BASE_PATH)\n",
    "        \n",
    "        if run_name == 'hypernymy_2000_50_mistral7B':\n",
    "            # has only 1 relation: use objects instead\n",
    "            objects_unsampled = df_instance_permutations['obj_label'].unique()\n",
    "            relations = np.random.choice(objects_unsampled, 10, replace=False)\n",
    "            print(f'Data: {run_name}, objects sampled: {len(relations)}/{len(objects_unsampled)}')\n",
    "        else:\n",
    "            relations = df_instance_permutations['orig_relation_id'].unique()\n",
    "            print(f'Relations: {relations.shape}')\n",
    "            print(f'Data: {run_name}, n_relations: {len(relations)}')\n",
    "        \n",
    "        for i, relation in enumerate(relations):\n",
    "            if run_name == 'hypernymy_2000_50_mistral7B':\n",
    "                df_relation = df_instance_permutations[df_instance_permutations['obj_label'] == relation]\n",
    "            else:\n",
    "                df_relation = df_instance_permutations[df_instance_permutations['orig_relation_id'] == relation]\n",
    "            \n",
    "            paraphrase_templates = df_relation['paraphrase_id'].unique()\n",
    "            try:\n",
    "                paraphrase_sample = np.random.choice(paraphrase_templates, 10, replace=False)\n",
    "            except ValueError:\n",
    "                print(f'Not enough paraphrases for relation {relation}: {len(paraphrase_templates)}')\n",
    "                paraphrase_sample = paraphrase_templates\n",
    "            for t, paraphrase_template in enumerate(paraphrase_sample):\n",
    "                if t== 0 and i == 0:\n",
    "                    print(f'unique t(r): {df_relation[\"paraphrase_id\"].nunique()}')\n",
    "                df_r_p = df_relation[df_relation['paraphrase_id'] == paraphrase_template]\n",
    "                pos_examples = df_r_p[df_r_p[\"label\"] == 'pos'].sample(n)\n",
    "                neg_examples = df_r_p[df_r_p[\"label\"] == 'neg'].sample(n)\n",
    "                \n",
    "                if i == 0 and t == 0:\n",
    "                    samples = pd.concat([pos_examples, neg_examples])\n",
    "                else:\n",
    "                    samples = pd.concat([samples, pos_examples, neg_examples])\n",
    "                \n",
    "        # reearange columns and save\n",
    "        samples = samples[['r_s_id', 'o_permutation_n', \n",
    "        'label', 'orig_relation_template', 'orig_relation_id',\n",
    "            'paraphrase_id', 'sequence_original',\n",
    "        'log_seq_prob', 's_r_t_id', 'p_t_s_r', 'p_t_over_paraphrases', 'p_t',\n",
    "        'rank_o', 'rank_o|p_t_s_r,r_s_t(r)_i', 'paraphrased_relation_template', 'sub_label', 'obj_label', 'sequence']]\n",
    "            \n",
    "            \n",
    "        samples.to_csv(BASE_PATH / f\"sequence_sample_{dataset_per_run[r]}.csv\", index=False)\n",
    "        print(BASE_PATH / f\"sequence_sample_{dataset_per_run[r]}.csv\")\n",
    "        print(len(samples))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypernymy: Context Evaluation\n",
    "Amount of times S is contained in context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject contained in context in: 533/574 = 92.86%\n"
     ]
    }
   ],
   "source": [
    "BASE_PATH_CODE = Path(f\"{HOME_PATH}/Py/MAI_Codebase/exp_3_set_proba/\") # TODO\n",
    "with open(BASE_PATH_CODE / \"s_contexts_hypernymy.json\") as f:\n",
    "    s_contexts_hypernymy = json.load(f)\n",
    "\n",
    "s_in_context = 0\n",
    "for s in s_contexts_hypernymy.keys():\n",
    "    if s.lower() in s_contexts_hypernymy[s].lower():\n",
    "        s_in_context += 1\n",
    "        \n",
    "result = s_in_context / len(s_contexts_hypernymy)\n",
    "print(f'Subject contained in context in: {s_in_context}/{len(s_contexts_hypernymy)} = {result*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grammar Postprocessing Errors\n",
    "- change of Subject or Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 hypernymy_2000_50_mistral7B\n",
      "Subjects affected by postprocessing: 6504/415440 %: 1.5655690352397458\n",
      "Objects affected by postprocessing: 0/415440 %: 0.0\n",
      "1 trex_test_2000_50_mistral7B\n",
      "Subjects affected by postprocessing: 710833/2293951 %: 30.987279152867693\n",
      "Objects affected by postprocessing: 18663/2293951 %: 0.8135744835003015\n",
      "2 PopQA_test_2000_50_mistral7B\n",
      "Subjects affected by postprocessing: 84059/267091 %: 31.47204510822154\n",
      "Objects affected by postprocessing: 68712/267091 %: 25.726063401612187\n"
     ]
    }
   ],
   "source": [
    "\n",
    "run_names = ['hypernymy_2000_50_mistral7B', 'trex_test_2000_50_mistral7B', 'PopQA_test_2000_50_mistral7B']\n",
    "dataset_per_run = ['hypernymy', 'trex', 'PopQA']\n",
    "\n",
    "for r, run_name in enumerate(run_names):\n",
    "    print(r, run_name)\n",
    "    df_stats, df_instance_permutations = get_data(run_name, BASE_PATH)\n",
    "    \n",
    "    subjects = df_instance_permutations['sub_label'].to_list()\n",
    "    objects = df_instance_permutations['obj_label'].to_list()\n",
    "    postprocessed_seqs = df_instance_permutations['sequence'].to_list()\n",
    "\n",
    "    s_mistakes, o_mistakes = [], []\n",
    "    for i in range(len(subjects)):\n",
    "        s = subjects[i].lower()\n",
    "        o = objects[i].lower()\n",
    "        seq = postprocessed_seqs[i].lower()\n",
    "        if s not in seq:\n",
    "            s_mistakes.append(1)\n",
    "        else:\n",
    "            s_mistakes.append(0)\n",
    "        if o not in seq:\n",
    "            o_mistakes.append(1)\n",
    "        else:\n",
    "            o_mistakes.append(0)\n",
    "            \n",
    "    df_instance_permutations['s_mistakes'] = s_mistakes\n",
    "    df_instance_permutations['o_mistakes'] = o_mistakes\n",
    "    \n",
    "    df_instance_permutations.to_csv(BASE_PATH / f\"grammar_postprocessing_mistakes_{dataset_per_run[r]}.csv\")\n",
    "    \n",
    "    s_mistakes_sum = np.array(s_mistakes).sum()\n",
    "    o_mistakes_sum = np.array(o_mistakes).sum()\n",
    "        \n",
    "    print(f\"Subjects affected by postprocessing: {s_mistakes_sum}/{len(subjects)} %: {s_mistakes_sum/len(subjects)*100}\" )\n",
    "    print(f\"Objects affected by postprocessing: {o_mistakes_sum}/{len(objects)} %: {o_mistakes_sum/len(objects)*100}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
